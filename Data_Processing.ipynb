{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessor For Neural Question Generator\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/christopherbate/nlp-squad-preprocessing/blob/master/squad_processer.py reference\n",
    "# I made many alterations to their code so it could match our specific needs. They mostly gave me an idea\n",
    "# of how the data was set up\n",
    "questions = []\n",
    "answers = []\n",
    "contexts = []\n",
    "for i in range(len(data['data'])):\n",
    "    temp = data['data'][i]['paragraphs']\n",
    "    for j in range(len(temp)):\n",
    "        context = temp[j]['context']\n",
    "        context = re.split(r\"[.!?]\",context)\n",
    "        context = [item.strip(\" \") for item in context]\n",
    "        if len(context) > 2:\n",
    "            context = context[:-1]\n",
    "        qas = temp[j]['qas']\n",
    "        for k in range(len(qas)):\n",
    "            question = qas[k]['question']\n",
    "            value = 0\n",
    "            answer = qas[k]['answers']\n",
    "            if not answer:\n",
    "                answer = qas[k]['plausible_answers'][0]['text']\n",
    "            else:\n",
    "                answer = answer[0]['text']  \n",
    "            question = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", question)\n",
    "            answer = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", answer)\n",
    "            #If the answer is in a sentence, when save up the sentence question pair\n",
    "            for item in context:\n",
    "                if answer in item:\n",
    "                    context = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\",item)\n",
    "                    questions.append(re.sub('\\s+',' ',question))\n",
    "                    answers.append(re.sub('\\s+',' ',answer))\n",
    "                    contexts.append(re.sub('\\s+',' ',context))\n",
    "                    break\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe\n",
    "dat = pd.DataFrame(answers)\n",
    "dat['question'] = questions\n",
    "dat.to_csv('neuralquestion.txt',sep='\\t',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now This will preprocess the Trump data\n",
    "tweets = pd.read_csv('trumpdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess: Elimiate all useless stuff and just grab tweets with certain keywords\n",
    "data = tweets[tweets.text.str.contains(\"Russia|Republican|Fake|News|Hillary|MAGA|CNN|President|War|USA|money|win|Democrats|America|huge|best|win|money\") == True]\n",
    "data = [re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",item) for item in data.iloc[:,0]]\n",
    "data = [\" \".join(item.split()) for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to right format\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv('TrumpData.txt',sep='\\t',header=False,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lign167",
   "language": "python",
   "name": "lign167"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
